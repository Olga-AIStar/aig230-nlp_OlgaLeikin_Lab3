{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91489c36",
   "metadata": {},
   "source": [
    "# AIG230 NLP (Week 3 Lab) — Notebook 2: Statistical Language Models (Train, Test, Evaluate)\n",
    "\n",
    "This notebook focuses on **n-gram Statistical Language Models (SLMs)**:\n",
    "- Train **unigram**, **bigram**, **trigram** models\n",
    "- Handle **OOV** with `<UNK>`\n",
    "- Apply **smoothing** (Add-k)\n",
    "- Evaluate with **cross-entropy** and **perplexity**\n",
    "- Do **next-word prediction** and simple **text generation**\n",
    "\n",
    "> Industry framing: even if modern systems use neural LMs, n-gram LMs are still useful for\n",
    "baselines, constrained domains, and for understanding evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad94cb39",
   "metadata": {},
   "source": [
    "### What is smoothing?\n",
    "\n",
    "Smoothing is a way to stop a language model from saying “this can never happen.”\n",
    "\n",
    "When we train a language model from data, it only knows what it has seen before.\n",
    "If it never saw a particular word sequence, the model would normally give it a probability of zero.\n",
    "\n",
    "Smoothing fixes that.\n",
    "### Why is this a problem without smoothing?\n",
    "\n",
    "Imagine the model learned English only by reading a small number of news articles.\n",
    "\n",
    "If it never saw:\n",
    "\n",
    "- “oil prices explode”\n",
    "\n",
    "the model would conclude:\n",
    "\n",
    "- “That sentence is impossible.”\n",
    "\n",
    "But as humans, we know it could happen. The model just hasn’t seen it yet.\n",
    "\n",
    "Without smoothing:\n",
    "\n",
    "- One unseen word makes the whole sentence probability zero\n",
    "\n",
    "- Evaluation breaks\n",
    "\n",
    "- The model is too confident and too brittle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a046e",
   "metadata": {},
   "source": [
    "## 0) Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "77ee526c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:05.951390Z",
     "start_time": "2026-02-02T01:04:05.911716Z"
    }
   },
   "source": [
    "\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Tuple, Dict\n"
   ],
   "outputs": [],
   "execution_count": 130
  },
  {
   "cell_type": "markdown",
   "id": "7fc428b4",
   "metadata": {},
   "source": [
    "## 1) Data: domain text you might see in real systems\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d207e4c",
   "metadata": {},
   "source": [
    "We use short texts that resemble:\n",
    "- release notes\n",
    "- incident summaries\n",
    "- operational runbooks\n",
    "- customer support messaging\n",
    "\n",
    "In practice, you would load thousands to millions of lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "fdb34582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.015924Z",
     "start_time": "2026-02-02T01:04:05.965197Z"
    }
   },
   "source": [
    "\n",
    "corpus = [\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "    \"vpn disconnects frequently after windows update\",\n",
    "    \"password reset link expired user cannot login\",\n",
    "    \"api requests timeout when latency spikes\",\n",
    "    \"portal returns 500 error after deployment\",\n",
    "    \"email delivery delayed messages queued\",\n",
    "    \"mfa prompt never arrives user stuck at login\",\n",
    "    \"wifi drops in meeting rooms access point reboot helps\",\n",
    "    \"outlook search not returning results index corrupted\",\n",
    "    \"printer driver install fails with error 1603\",\n",
    "    \"teams calls choppy audio jitter high\",\n",
    "    \"permission denied accessing shared drive though in correct group\",\n",
    "    \"battery drains fast after bios update power settings unchanged\",\n",
    "    \"push notifications not working on android app\",\n",
    "    \"mailbox full cannot receive emails auto archive not running\",\n",
    "]\n",
    "\n",
    "# Train/test split at sentence level\n",
    "random.seed(42)\n",
    "random.shuffle(corpus)\n",
    "split = int(0.75 * len(corpus))\n",
    "train_texts = corpus[:split]\n",
    "test_texts = corpus[split:]\n",
    "\n",
    "len(train_texts), len(test_texts), train_texts[:2], test_texts[:2]\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21,\n",
       " 7,\n",
       " ['email delivery delayed messages queued',\n",
       "  'api requests timeout when latency spikes'],\n",
       " ['printer driver install fails with error 1603',\n",
       "  'outlook search not returning results index corrupted'])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 131
  },
  {
   "cell_type": "markdown",
   "id": "de9f9947",
   "metadata": {},
   "source": [
    "## 2) Tokenization + special tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c285f1d",
   "metadata": {},
   "source": [
    "We will:\n",
    "- lowercase\n",
    "- keep alphanumerics\n",
    "- split on whitespace\n",
    "- add sentence boundary tokens: `<s>` and `</s>`\n",
    "\n",
    "We will also map rare tokens to `<UNK>` based on training frequency.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "058f87da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.069588Z",
     "start_time": "2026-02-02T01:04:06.017654Z"
    }
   },
   "source": [
    "\n",
    "def tokenize(text: str) -> List[str]:\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z0-9\\s]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    #print(text)\n",
    "    return text.split()\n",
    "\n",
    "def add_boundaries(tokens: List[str], n: int) -> List[str]:\n",
    "    # For n-grams, prepend (n-1) start tokens for simpler context handling\n",
    "    return [\"<s>\"]*(n-1) + tokens + [\"</s>\"]\n",
    "\n",
    "# Example\n",
    "tokens = tokenize(\"Printer driver install fails with error 1603\")\n",
    "add_boundaries(tokens, n=3)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " '<s>',\n",
       " 'printer',\n",
       " 'driver',\n",
       " 'install',\n",
       " 'fails',\n",
       " 'with',\n",
       " 'error',\n",
       " '1603',\n",
       " '</s>']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 132
  },
  {
   "cell_type": "markdown",
   "id": "25308557",
   "metadata": {},
   "source": [
    "## 3) Build vocabulary and handle OOV with <UNK>\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3338f0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.113817Z",
     "start_time": "2026-02-02T01:04:06.071683Z"
    }
   },
   "source": [
    "\n",
    "# Build vocab from training data\n",
    "train_tokens_flat = []\n",
    "for t in train_texts:\n",
    "    train_tokens_flat.extend(tokenize(t))\n",
    "\n",
    "print(len(train_tokens_flat), train_tokens_flat)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154 ['email', 'delivery', 'delayed', 'messages', 'queued', 'api', 'requests', 'timeout', 'when', 'latency', 'spikes', 'permission', 'denied', 'accessing', 'shared', 'drive', 'though', 'in', 'correct', 'group', 'outlook', 'search', 'not', 'returning', 'results', 'index', 'corrupted', 'mailbox', 'full', 'cannot', 'receive', 'emails', 'auto', 'archive', 'not', 'running', 'wifi', 'drops', 'in', 'meeting', 'rooms', 'access', 'point', 'reboot', 'helps', 'mfa', 'prompt', 'never', 'arrives', 'user', 'stuck', 'at', 'login', 'battery', 'drains', 'fast', 'after', 'bios', 'update', 'power', 'settings', 'unchanged', 'vpn', 'disconnects', 'frequently', 'after', 'windows', 'update', 'teams', 'calls', 'choppy', 'audio', 'jitter', 'high', 'permission', 'denied', 'accessing', 'shared', 'drive', 'though', 'in', 'correct', 'group', 'push', 'notifications', 'not', 'working', 'on', 'android', 'app', 'mfa', 'prompt', 'never', 'arrives', 'user', 'stuck', 'at', 'login', 'password', 'reset', 'link', 'expired', 'user', 'cannot', 'login', 'battery', 'drains', 'fast', 'after', 'bios', 'update', 'power', 'settings', 'unchanged', 'password', 'reset', 'link', 'expired', 'user', 'cannot', 'login', 'mailbox', 'full', 'cannot', 'receive', 'emails', 'auto', 'archive', 'not', 'running', 'api', 'requests', 'timeout', 'when', 'latency', 'spikes', 'portal', 'returns', '500', 'error', 'after', 'deployment', 'push', 'notifications', 'not', 'working', 'on', 'android', 'app', 'email', 'delivery', 'delayed', 'messages', 'queued']\n"
     ]
    }
   ],
   "execution_count": 133
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.127340Z",
     "start_time": "2026-02-02T01:04:06.116715Z"
    }
   },
   "cell_type": "code",
   "source": "freq = Counter(train_tokens_flat)",
   "id": "74aa7f488b317cd1",
   "outputs": [],
   "execution_count": 134
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.158748Z",
     "start_time": "2026-02-02T01:04:06.128300Z"
    }
   },
   "cell_type": "code",
   "source": "len(freq.items())",
   "id": "7930afb0bc0dd98a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 135
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:32.662605Z",
     "start_time": "2026-02-02T01:04:32.610650Z"
    }
   },
   "cell_type": "code",
   "source": [
    "count = 0\n",
    "word_count = 2\n",
    "for w,c in freq.items():\n",
    "    if c>= word_count:\n",
    "        count += 1\n",
    "        #print (w,c)\n",
    "\n",
    "print (f'Tot words: {count} that frequency >= {word_count} out of {len(freq)} words')"
   ],
   "id": "aab2f7a8d275815d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tot words: 56 that frequency >= 2 out of 85 words\n"
     ]
    }
   ],
   "execution_count": 150
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.201176Z",
     "start_time": "2026-02-02T01:04:06.190467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Typical practical rule: map tokens with frequency <= 1 to <UNK> in small corpora\n",
    "min_count = word_count\n",
    "vocab = {w for w, c in freq.items() if c >= min_count}\n",
    "vocab |= {\"<UNK>\", \"<s>\", \"</s>\"}"
   ],
   "id": "9e337445d36fa65b",
   "outputs": [],
   "execution_count": 137
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.234996Z",
     "start_time": "2026-02-02T01:04:06.203762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(vocab))\n",
    "vocab"
   ],
   "id": "5dcbd290da7c4b96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'500',\n",
       " '</s>',\n",
       " '<UNK>',\n",
       " '<s>',\n",
       " 'access',\n",
       " 'accessing',\n",
       " 'after',\n",
       " 'android',\n",
       " 'api',\n",
       " 'app',\n",
       " 'archive',\n",
       " 'arrives',\n",
       " 'at',\n",
       " 'audio',\n",
       " 'auto',\n",
       " 'battery',\n",
       " 'bios',\n",
       " 'calls',\n",
       " 'cannot',\n",
       " 'choppy',\n",
       " 'correct',\n",
       " 'corrupted',\n",
       " 'delayed',\n",
       " 'delivery',\n",
       " 'denied',\n",
       " 'deployment',\n",
       " 'disconnects',\n",
       " 'drains',\n",
       " 'drive',\n",
       " 'drops',\n",
       " 'email',\n",
       " 'emails',\n",
       " 'error',\n",
       " 'expired',\n",
       " 'fast',\n",
       " 'frequently',\n",
       " 'full',\n",
       " 'group',\n",
       " 'helps',\n",
       " 'high',\n",
       " 'in',\n",
       " 'index',\n",
       " 'jitter',\n",
       " 'latency',\n",
       " 'link',\n",
       " 'login',\n",
       " 'mailbox',\n",
       " 'meeting',\n",
       " 'messages',\n",
       " 'mfa',\n",
       " 'never',\n",
       " 'not',\n",
       " 'notifications',\n",
       " 'on',\n",
       " 'outlook',\n",
       " 'password',\n",
       " 'permission',\n",
       " 'point',\n",
       " 'portal',\n",
       " 'power',\n",
       " 'prompt',\n",
       " 'push',\n",
       " 'queued',\n",
       " 'reboot',\n",
       " 'receive',\n",
       " 'requests',\n",
       " 'reset',\n",
       " 'results',\n",
       " 'returning',\n",
       " 'returns',\n",
       " 'rooms',\n",
       " 'running',\n",
       " 'search',\n",
       " 'settings',\n",
       " 'shared',\n",
       " 'spikes',\n",
       " 'stuck',\n",
       " 'teams',\n",
       " 'though',\n",
       " 'timeout',\n",
       " 'unchanged',\n",
       " 'update',\n",
       " 'user',\n",
       " 'vpn',\n",
       " 'when',\n",
       " 'wifi',\n",
       " 'windows',\n",
       " 'working'}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 138
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.256950Z",
     "start_time": "2026-02-02T01:04:06.237459Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def replace_oov(tokens: List[str], vocab: set) -> List[str]:\n",
    "    return [tok if tok in vocab else \"<UNK>\" for tok in tokens]\n",
    "\n",
    "# Show OOV effect\n",
    "sample = tokenize(test_texts[0])\n",
    "sample, replace_oov(sample, vocab)\n"
   ],
   "id": "a87903792ad4b750",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['printer', 'driver', 'install', 'fails', 'with', 'error', '1603'],\n",
       " ['<UNK>', '<UNK>', '<UNK>', '<UNK>', '<UNK>', 'error', '<UNK>'])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 139
  },
  {
   "cell_type": "markdown",
   "id": "759444a0",
   "metadata": {},
   "source": [
    "## 4) Train n-gram counts (unigram, bigram, trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21eac8fa",
   "metadata": {},
   "source": [
    "We will compute:\n",
    "- `ngram_counts[(w1,...,wn)]`\n",
    "- `context_counts[(w1,...,w_{n-1})]`\n",
    "\n",
    "Then probability:\n",
    "\\ndefault:  P(w_n | context) = count(context + w_n) / count(context)\n",
    "\n",
    "This fails when an n-gram is unseen, so we add smoothing.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "33672bdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.268244Z",
     "start_time": "2026-02-02T01:04:06.259826Z"
    }
   },
   "source": [
    "def get_ngrams(tokens: List[str], n: int):\n",
    "    return[tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "\n",
    "def train_ngram_counts(texts: List[str], n: int, vocab: set):\n",
    "    ngrams_counts = Counter()\n",
    "    context_counts = Counter()\n",
    "\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n=n)\n",
    "\n",
    "        #print(toks)\n",
    "\n",
    "        for ng in get_ngrams(toks, n):\n",
    "            ngrams_counts[ng] += 1\n",
    "            context = ng[:-1]\n",
    "            context_counts[context] += 1\n",
    "    return ngrams_counts, context_counts"
   ],
   "outputs": [],
   "execution_count": 140
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.285091Z",
     "start_time": "2026-02-02T01:04:06.269078Z"
    }
   },
   "cell_type": "code",
   "source": [
    "uni_counts, uni_ctx = train_ngram_counts(train_texts, n=1, vocab=vocab)\n",
    "bi_counts, bi_ctx   = train_ngram_counts(train_texts, n=2, vocab=vocab)\n",
    "tri_counts, tri_ctx = train_ngram_counts(train_texts, n=3, vocab=vocab)\n",
    "\n",
    "print('uni ',len(uni_counts), len(uni_ctx))\n",
    "print('bi ',len(bi_counts), len(bi_ctx))\n",
    "print('tri',len(tri_counts), len(tri_ctx))"
   ],
   "id": "82ec652a14e2756c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uni  86 1\n",
      "bi  106 86\n",
      "tri 107 95\n"
     ]
    }
   ],
   "execution_count": 141
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.301663Z",
     "start_time": "2026-02-02T01:04:06.285752Z"
    }
   },
   "cell_type": "code",
   "source": "bi_ctx",
   "id": "82af98c13f9402aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({('<s>',): 21,\n",
       "         ('not',): 5,\n",
       "         ('cannot',): 4,\n",
       "         ('user',): 4,\n",
       "         ('login',): 4,\n",
       "         ('after',): 4,\n",
       "         ('in',): 3,\n",
       "         ('update',): 3,\n",
       "         ('email',): 2,\n",
       "         ('delivery',): 2,\n",
       "         ('delayed',): 2,\n",
       "         ('messages',): 2,\n",
       "         ('queued',): 2,\n",
       "         ('api',): 2,\n",
       "         ('requests',): 2,\n",
       "         ('timeout',): 2,\n",
       "         ('when',): 2,\n",
       "         ('latency',): 2,\n",
       "         ('spikes',): 2,\n",
       "         ('permission',): 2,\n",
       "         ('denied',): 2,\n",
       "         ('accessing',): 2,\n",
       "         ('shared',): 2,\n",
       "         ('drive',): 2,\n",
       "         ('though',): 2,\n",
       "         ('correct',): 2,\n",
       "         ('group',): 2,\n",
       "         ('mailbox',): 2,\n",
       "         ('full',): 2,\n",
       "         ('receive',): 2,\n",
       "         ('emails',): 2,\n",
       "         ('auto',): 2,\n",
       "         ('archive',): 2,\n",
       "         ('running',): 2,\n",
       "         ('mfa',): 2,\n",
       "         ('prompt',): 2,\n",
       "         ('never',): 2,\n",
       "         ('arrives',): 2,\n",
       "         ('stuck',): 2,\n",
       "         ('at',): 2,\n",
       "         ('battery',): 2,\n",
       "         ('drains',): 2,\n",
       "         ('fast',): 2,\n",
       "         ('bios',): 2,\n",
       "         ('power',): 2,\n",
       "         ('settings',): 2,\n",
       "         ('unchanged',): 2,\n",
       "         ('push',): 2,\n",
       "         ('notifications',): 2,\n",
       "         ('working',): 2,\n",
       "         ('on',): 2,\n",
       "         ('android',): 2,\n",
       "         ('app',): 2,\n",
       "         ('password',): 2,\n",
       "         ('reset',): 2,\n",
       "         ('link',): 2,\n",
       "         ('expired',): 2,\n",
       "         ('outlook',): 1,\n",
       "         ('search',): 1,\n",
       "         ('returning',): 1,\n",
       "         ('results',): 1,\n",
       "         ('index',): 1,\n",
       "         ('corrupted',): 1,\n",
       "         ('wifi',): 1,\n",
       "         ('drops',): 1,\n",
       "         ('meeting',): 1,\n",
       "         ('rooms',): 1,\n",
       "         ('access',): 1,\n",
       "         ('point',): 1,\n",
       "         ('reboot',): 1,\n",
       "         ('helps',): 1,\n",
       "         ('vpn',): 1,\n",
       "         ('disconnects',): 1,\n",
       "         ('frequently',): 1,\n",
       "         ('windows',): 1,\n",
       "         ('teams',): 1,\n",
       "         ('calls',): 1,\n",
       "         ('choppy',): 1,\n",
       "         ('audio',): 1,\n",
       "         ('jitter',): 1,\n",
       "         ('high',): 1,\n",
       "         ('portal',): 1,\n",
       "         ('returns',): 1,\n",
       "         ('500',): 1,\n",
       "         ('error',): 1,\n",
       "         ('deployment',): 1})"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 142
  },
  {
   "cell_type": "markdown",
   "id": "8e3ba7c8",
   "metadata": {},
   "source": [
    "## 5) Add-k smoothing and probability function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed806986",
   "metadata": {},
   "source": [
    "### What does Add-k smoothing do?\n",
    "Add-k smoothing tells the model:\n",
    "\n",
    "- “Even if you didn’t see something, assume it could still happen a little bit.”\n",
    "\n",
    "It does this by:\n",
    "\n",
    "- Giving every possible next word a tiny amount of probability\n",
    "\n",
    "- Not just the ones seen in training\n",
    "\n",
    "So instead of:\n",
    "\n",
    "- seen → possible\n",
    "\n",
    "- unseen → impossible\n",
    "\n",
    "We get:\n",
    "\n",
    "- seen → more likely\n",
    "\n",
    "- unseen → less likely, but still possible\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea279f3",
   "metadata": {},
   "source": [
    "### Why is it called Add-k?\n",
    "\n",
    "Because we add a small number k to every word count.\n",
    "\n",
    "Think of it as:\n",
    "\n",
    "- adding a tiny “imaginary observation” for every word\n",
    "\n",
    "- so no word ever has zero probability\n",
    "\n",
    "When k is small (like 0.1 or 0.5), it gently smooths the probabilities instead of overpowering real data."
   ]
  },
  {
   "cell_type": "code",
   "id": "de565994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.319055Z",
     "start_time": "2026-02-02T01:04:06.302520Z"
    }
   },
   "source": [
    "# This function calculates the probability of a word appearing next, given the previous words, while making sure the probability is never zero.\n",
    "def prob_addk(ngram: Tuple[str, ...], ngram_counts: Counter, context_counts: Counter, V: int, k: float = 0.5) -> float:\n",
    "    context = ngram[:-1]  #“Give me everything except the last element”\n",
    "    return (ngram_counts[ngram] + k) / (context_counts[context] + k * V)\n",
    "\n",
    "V = len(vocab)\n",
    "# Example: P(\"login\" | \"<s>\") in bigram model\n",
    "# How likely is the word \"login\" to come after \"<s>\"?\n",
    "example = (\"<s>\", \"gold\")\n",
    "prob_addk(example, bi_counts, bi_ctx, V, k=0.5)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007692307692307693"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 143
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.328279Z",
     "start_time": "2026-02-02T01:04:06.322139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prob_backoff(trigram,\n",
    "            tri_counts, tri_ctx,\n",
    "            bi_counts, bi_ctx,\n",
    "            uni_counts, uni_ctx,\n",
    "            vocab,\n",
    "            k=0.5\n",
    "            ):\n",
    "    w1, w2, w3 = trigram\n",
    "    V = len(vocab)\n",
    "\n",
    "    if tri_counts[trigram] > 0 and tri_ctx[(w1,w2)] > 0:\n",
    "        return prob_addk(trigram, tri_counts, tri_ctx, V, k), 'tri'\n",
    "\n",
    "    bigram = (w2,w3)\n",
    "\n",
    "    if bi_counts[bigram] > 0 and bi_ctx[(w2,)] > 0:\n",
    "        return prob_addk(bigram, bi_counts, bi_ctx, V, k), 'bi'\n",
    "\n",
    "    uni = (w1,)\n",
    "    return prob_addk(uni, uni_counts, uni_ctx, V, k), 'uni'\n"
   ],
   "id": "a87aff5b6d5498a7",
   "outputs": [],
   "execution_count": 144
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.345313Z",
     "start_time": "2026-02-02T01:04:06.328936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "example = (\"vpn\" , \"disconnects\",  \"frequently\")\n",
    "prob_backoff(example,tri_counts, tri_ctx, bi_counts, bi_ctx, uni_counts, uni_ctx, vocab, k=0.5)"
   ],
   "id": "659dd162d1758b92",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.03333333333333333, 'tri')"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 145
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 6) Evaluate: cross-entropy and perplexity on test set\n",
   "id": "a2377e679a530a00"
  },
  {
   "cell_type": "markdown",
   "id": "3c8426d9",
   "metadata": {},
   "source": [
    "We evaluate an LM by how well it predicts held-out text.\n",
    "\n",
    "Cross-entropy (average negative log probability):\n",
    "H = - (1/N) * sum log2 P(w_i | context)\n",
    "\n",
    "Perplexity:\n",
    "PP = 2^H\n",
    "\n",
    "Lower perplexity is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c2d03099",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.360743Z",
     "start_time": "2026-02-02T01:04:06.346629Z"
    }
   },
   "source": [
    "def evaluate_perplexity(texts: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k: float = 0.5) -> float:\n",
    "    V = len(vocab)\n",
    "    log2_probs = []\n",
    "    token_count = 0\n",
    "\n",
    "    for text in texts:\n",
    "        toks = replace_oov(tokenize(text), vocab)\n",
    "        toks = add_boundaries(toks, n)\n",
    "        ngrams = get_ngrams(toks, n)\n",
    "        for ng in ngrams:\n",
    "            p = prob_addk(ng, ngram_counts, context_counts, V, k=k)\n",
    "            log2_probs.append(math.log(p, 2))\n",
    "            token_count += 1\n",
    "\n",
    "    H = -sum(log2_probs) / token_count\n",
    "    PP = 2 ** H\n",
    "    return PP\n",
    "\n",
    "pp_uni = evaluate_perplexity(test_texts, n=1, ngram_counts=uni_counts, context_counts=uni_ctx, vocab=vocab, k=0.5)\n",
    "pp_bi  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=0.5)\n",
    "pp_tri = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=0.5)\n",
    "\n",
    "pp_uni, pp_bi, pp_tri"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120.30682300277988, 43.30067859488039, 43.029015025061675)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "cell_type": "markdown",
   "id": "9ef338ce",
   "metadata": {},
   "source": [
    "## 7) Next-word prediction (top-k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d202f5",
   "metadata": {},
   "source": [
    "Given a context, compute the probability of each candidate next token and return the top-k.\n",
    "\n",
    "This mirrors:\n",
    "- autocomplete in constrained domains\n",
    "- template suggestion systems\n",
    "- command prediction in runbooks\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "11363d81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.379637Z",
     "start_time": "2026-02-02T01:04:06.361367Z"
    }
   },
   "source": [
    "def next_word_topk(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5, top_k: int = 5):\n",
    "    # Context length should be n-1\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    candidates = []\n",
    "    for w in vocab:\n",
    "        if w in {\"<s>\"}:\n",
    "            continue\n",
    "        ng = context + (w,)\n",
    "        p = prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth)\n",
    "        candidates.append((w, p))\n",
    "    candidates.sort(key=lambda x: -x[1])\n",
    "    return candidates[:top_k]\n",
    "\n",
    "# Bigram: context is 1 token\n",
    "next_word_topk([\"<s>\"], n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab, top_k=8)\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('battery', 0.038461538461538464),\n",
       " ('email', 0.038461538461538464),\n",
       " ('push', 0.038461538461538464),\n",
       " ('password', 0.038461538461538464),\n",
       " ('mfa', 0.038461538461538464),\n",
       " ('permission', 0.038461538461538464),\n",
       " ('api', 0.038461538461538464),\n",
       " ('mailbox', 0.038461538461538464)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 147
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:17:14.344839Z",
     "start_time": "2026-02-02T01:17:14.284695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Create a function that returns top-5 next words given a phrase like: \"user cannot\".\n",
    "\n",
    "phrase= ['user', 'cannot']\n",
    "next_word_topk(phrase, n=2, ngram_counts=bi_counts, context_counts=bi_ctx, vocab=vocab)"
   ],
   "id": "1e84a443824106af",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('receive', 0.052083333333333336),\n",
       " ('login', 0.052083333333333336),\n",
       " ('battery', 0.010416666666666666),\n",
       " ('update', 0.010416666666666666),\n",
       " ('500', 0.010416666666666666)]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 151
  },
  {
   "cell_type": "markdown",
   "id": "9672e1e9",
   "metadata": {},
   "source": [
    "## 8) Simple generation (bigram or trigram)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd41fb",
   "metadata": {},
   "source": [
    "Text generation is not the main goal in SLMs, but it helps you verify:\n",
    "- boundary handling\n",
    "- smoothing\n",
    "- OOV decisions\n",
    "\n",
    "We will sample tokens until we hit `</s>`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "7c8d1acb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.396598Z",
     "start_time": "2026-02-02T01:04:06.381015Z"
    }
   },
   "source": [
    "\n",
    "def sample_next(context_tokens: List[str], n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, k_smooth: float = 0.5):\n",
    "    V = len(vocab)\n",
    "    context = tuple(context_tokens[-(n-1):]) if n > 1 else tuple()\n",
    "    words = [w for w in vocab if w != \"<s>\"]\n",
    "    probs = []\n",
    "    for w in words:\n",
    "        ng = context + (w,)\n",
    "        probs.append(prob_addk(ng, ngram_counts, context_counts, V, k=k_smooth))\n",
    "    # Normalize\n",
    "    s = sum(probs)\n",
    "    probs = [p/s for p in probs]\n",
    "    return random.choices(words, weights=probs, k=1)[0]\n",
    "\n",
    "def generate(n: int, ngram_counts: Counter, context_counts: Counter, vocab: set, max_len: int = 20, k_smooth: float = 0.5):\n",
    "    tokens = [\"<s>\"]*(n-1) if n > 1 else []\n",
    "    out = []\n",
    "    for _ in range(max_len):\n",
    "        w = sample_next(tokens, n, ngram_counts, context_counts, vocab, k_smooth=k_smooth)\n",
    "        if w == \"</s>\":\n",
    "            break\n",
    "        out.append(w)\n",
    "        tokens.append(w)\n",
    "    return \" \".join(out)\n",
    "\n",
    "for _ in range(5):\n",
    "    print(\"BIGRAM:\", generate(2, bi_counts, bi_ctx, vocab, max_len=18))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIGRAM: high permission battery on android delayed rooms reboot unchanged point point fast requests on android notifications search after\n",
      "BIGRAM: messages user requests error <UNK> settings spikes\n",
      "BIGRAM: deployment correct power email power choppy delayed after\n",
      "BIGRAM: though mailbox when full accessing teams rooms returns corrupted when queued drops group running\n",
      "BIGRAM: battery meeting power\n"
     ]
    }
   ],
   "execution_count": 148
  },
  {
   "cell_type": "markdown",
   "id": "83db5405",
   "metadata": {},
   "source": [
    "## 9) Model comparison: effect of n and smoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7486afd",
   "metadata": {},
   "source": [
    "Try different `k` values. Notes:\n",
    "- `k=1.0` is Laplace smoothing (often too strong)\n",
    "- smaller `k` (like 0.1 to 0.5) is often better\n",
    "\n",
    "In real corpora, trigrams often beat bigrams, but require more data.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4eb25609",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-02T01:04:06.412356Z",
     "start_time": "2026-02-02T01:04:06.399182Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "for k in [1.0, 0.5, 0.1, 0.01]:\n",
    "    pp_bi_k  = evaluate_perplexity(test_texts, n=2, ngram_counts=bi_counts,  context_counts=bi_ctx,  vocab=vocab, k=k)\n",
    "    pp_tri_k = evaluate_perplexity(test_texts, n=3, ngram_counts=tri_counts, context_counts=tri_ctx, vocab=vocab, k=k)\n",
    "    print(f\"k={k:>4}:  bigram PP={pp_bi_k:,.2f}   trigram PP={pp_tri_k:,.2f}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1.0:  bigram PP=55.88   trigram PP=55.70\n",
      "k= 0.5:  bigram PP=43.30   trigram PP=43.03\n",
      "k= 0.1:  bigram PP=20.60   trigram PP=20.06\n",
      "k=0.01:  bigram PP=8.96   trigram PP=8.03\n"
     ]
    }
   ],
   "execution_count": 149
  },
  {
   "cell_type": "markdown",
   "id": "6be49abe",
   "metadata": {},
   "source": [
    "## Exercises (do these during lab)\n",
    "1) Add 20 more realistic domain sentences to the corpus and re-run training/evaluation.  \n",
    "2) Change `min_count` (OOV threshold) and explain how perplexity changes.  \n",
    "3) Implement **backoff**: if a trigram is unseen, fall back to bigram; if unseen,\n",
    "4) Create a function that returns top-5 next words given a phrase like: \"user cannot\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f5c844",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
